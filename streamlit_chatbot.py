import streamlit as st
import pandas as pd
from difflib import get_close_matches
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.set_page_config(page_title="Soros æŠ•èµ„é—®ç­” Chatbot")

# åŠ è½½æ¨¡å‹å’Œæ•°æ®
@st.cache_resource
def load_model():
    model = AutoModelForSeq2SeqLM.from_pretrained("./soros-model").to("cpu")
    tokenizer = AutoTokenizer.from_pretrained("./soros-model")
    return model, tokenizer

@st.cache_data
def load_qa_data():
    df = pd.read_csv("Soros-QNA-Pairs.csv")
    questions = df["Question"].dropna().tolist()
    answers = df["Answer"].dropna().tolist()
    return questions, answers

model, tokenizer = load_model()
questions, answers = load_qa_data()

# å›ç­”é€»è¾‘
def get_finetuned_response(prompt):
    inputs = tokenizer(prompt, return_tensors="pt").to("cpu")
    outputs = model.generate(**inputs, max_new_tokens=100)
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response

def get_answer(user_input):
    match = get_close_matches(user_input, questions, n=1, cutoff=0.6)
    if match:
        return answers[questions.index(match[0])]
    else:
        return get_finetuned_response(user_input)

# Streamlit UI
st.title("ğŸ’¬ ç´¢ç½—æ–¯æŠ•èµ„ç†å¿µé—®ç­”æœºå™¨äºº")

user_input = st.text_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼ˆä¾‹å¦‚ï¼šç´¢ç½—æ–¯æ€ä¹ˆçœ‹é‡‘èå¸‚åœºå±æœºï¼Ÿï¼‰")

if user_input:
    with st.spinner("æ€è€ƒä¸­..."):
        response = get_answer(user_input)
    st.markdown("**ğŸ’¡ Chatbot å›ç­”ï¼š**")
    st.success(response)

st.markdown("---")
st.caption("æœ¬æ¨¡å‹åŸºäºä¹”æ²»Â·ç´¢ç½—æ–¯çš„æŠ•èµ„ç†å¿µè¿›è¡Œå¾®è°ƒï¼Œä»…ä¾›å­¦ä¹ å‚è€ƒã€‚")
